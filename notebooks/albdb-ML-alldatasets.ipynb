{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hate = pd.read_csv(\"../raw_data/hate-speech.csv\")\n",
    "data_cognitive = pd.read_csv(\"../raw_data/cognitive-bias.csv\")\n",
    "data_fake = pd.read_csv(\"../raw_data/fake-news.csv\")\n",
    "data_gender = pd.read_csv(\"../raw_data/gender-bias.csv\")\n",
    "data_linguistic = pd.read_csv(\"../raw_data/linguistic-bias.csv\")\n",
    "data_racial = pd.read_csv(\"../raw_data/racial-bias.csv\")\n",
    "data_political = pd.read_csv(\"../raw_data/political-bias.csv\")\n",
    "data_political = data_political.dropna()\n",
    "data_textlevel = pd.read_csv(\"../raw_data/text-level-bias.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ds = {\n",
    "    'ds-hate': data_hate,\n",
    "    'ds-cognitive': data_cognitive,\n",
    "    'ds-fake': data_fake, \n",
    "    'ds-political':data_political, \n",
    "    'ds-gender': data_gender, \n",
    "    'ds-linguistic': data_linguistic, \n",
    "    'ds-text': data_textlevel, \n",
    "    'ds-racial': data_racial\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds-hate : 339010 rows\n",
      "ds-cognitive : 7092 rows\n",
      "ds-fake : 8542 rows\n",
      "ds-political : 17703 rows\n",
      "ds-gender : 17940 rows\n",
      "ds-linguistic : 401862 rows\n",
      "ds-text : 9018 rows\n",
      "ds-racial : 9788 rows\n"
     ]
    }
   ],
   "source": [
    "for ds_name, ds in dict_ds.items():\n",
    "    print(f\"{ds_name} : {ds.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ds_small = {\n",
    "    'ds-cognitive': data_cognitive,\n",
    "    'ds-fake': data_fake, \n",
    "    'ds-political':data_political, \n",
    "    'ds-gender': data_gender, \n",
    "    'ds-text': data_textlevel, \n",
    "    'ds-racial': data_racial\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ds_large = {\n",
    "    'ds-hate': data_hate,\n",
    "    'ds-linguistic': data_linguistic, \n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def cleaning(series):\n",
    "    def cleaning_sentence(sentence):\n",
    "        \"\"\" takes a sentence (string) as input and returns\n",
    "        same string but fully cleaned \"\"\"\n",
    "        \n",
    "        # Basic cleaning\n",
    "        sentence = sentence.strip() ## remove whitespaces\n",
    "        sentence = sentence.lower() ## lowercase \n",
    "        sentence = ''.join(char for char in sentence if not char.isdigit()) ## remove numbers\n",
    "        \n",
    "        # Advanced cleaning\n",
    "        for punctuation in string.punctuation:\n",
    "            sentence = sentence.replace(punctuation, '') ## remove punctuation\n",
    "        \n",
    "        tokenized_sentence = word_tokenize(sentence) ## tokenize \n",
    "        \n",
    "        stop_words = set(stopwords.words('english')) ## define stopwords\n",
    "        \n",
    "        tokenized_sentence_cleaned = [ ## remove stopwords\n",
    "            w for w in tokenized_sentence if not w in stop_words\n",
    "        ]\n",
    "        \n",
    "        # Lemmatizing\n",
    "        lemmatized_verbs = [WordNetLemmatizer().lemmatize(word, pos = \"v\") for word in tokenized_sentence_cleaned]\n",
    "        lemmatized_nouns = [WordNetLemmatizer().lemmatize(word, pos = \"n\") for word in lemmatized_verbs]\n",
    "        lemmatized_adj = [WordNetLemmatizer().lemmatize(word, pos = \"a\") for word in lemmatized_nouns]\n",
    "        lemmatized_adv = [WordNetLemmatizer().lemmatize(word, pos = \"r\") for word in lemmatized_adj]\n",
    "        \n",
    "        cleaned_sentence = ' '.join(word for word in lemmatized_adv)\n",
    "        \n",
    "        return cleaned_sentence\n",
    "    \n",
    "    return series.apply(cleaning_sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic Reg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 small datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds-cognitive: accuracy of 58.4%\n",
      "ds-fake: accuracy of 62.8%\n",
      "ds-political: accuracy of 68.4%\n",
      "ds-gender: accuracy of 80.2%\n",
      "ds-text: accuracy of 69.0%\n",
      "ds-racial: accuracy of 70.5%\n",
      "{'ds-cognitive': 58.4, 'ds-fake': 62.8, 'ds-political': 68.4, 'ds-gender': 80.2, 'ds-text': 69.0, 'ds-racial': 70.5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "dict_perf = {}\n",
    "\n",
    "for ds_name, ds in dict_ds_small.items():\n",
    "    \n",
    "    # defining X and y\n",
    "    X = ds['text']\n",
    "    y = ds['label']\n",
    "    \n",
    "    # train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    # make a pipeline and fit it\n",
    "    cleaner = FunctionTransformer(cleaning)\n",
    "    vectorizer = TfidfVectorizer(min_df=10, max_df=0.7, ngram_range=(1, 1))\n",
    "    model = LogisticRegression(solver='liblinear',C=0.1)\n",
    "    pipeline = make_pipeline(cleaner, vectorizer, model)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # evaluate the pipeline\n",
    "    predictions = pipeline.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    dict_perf[ds_name] = round(accuracy*100,1)\n",
    "    \n",
    "    print(f\"{ds_name}: accuracy of {round(accuracy*100,1)}%\")\n",
    "\n",
    "print(dict_perf)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds-hate: accuracy of 85.3%\n",
      "ds-linguistic: accuracy of 62.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "dict_perf_large = {}\n",
    "\n",
    "\n",
    "for ds_name, ds in dict_ds_large.items():\n",
    "    \n",
    "    # defining X and y and taking a subset of the full dataset\n",
    "    X_full = ds['text']\n",
    "    y_full = ds['label']\n",
    "    X, _, y, _ = train_test_split(X_full, y_full, test_size=0.75, random_state=42)\n",
    "    \n",
    "    # train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    # make a pipeline and fit it\n",
    "    cleaner = FunctionTransformer(cleaning)\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,1), min_df=30, max_df=0.8)\n",
    "    model = LogisticRegression(solver='liblinear', penalty='l1', C=1)\n",
    "    pipeline = make_pipeline(cleaner, vectorizer, model)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # evaluate the pipeline\n",
    "    predictions = pipeline.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    dict_perf[ds_name] = round(accuracy*100,1)\n",
    "    \n",
    "    print(f\"{ds_name}: accuracy of {round(accuracy*100,1)}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Naive Bayes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 small datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds-cognitive: accuracy of 58.0%\n",
      "ds-fake: accuracy of 62.7%\n",
      "ds-political: accuracy of 70.0%\n",
      "ds-gender: accuracy of 78.1%\n",
      "ds-text: accuracy of 66.8%\n",
      "ds-racial: accuracy of 70.6%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "for ds_name, ds in dict_ds_small.items():\n",
    "    \n",
    "    # defining X and y\n",
    "    X = ds['text']\n",
    "    y = ds['label']\n",
    "    \n",
    "    # train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    # make a pipeline and fit it\n",
    "    cleaner = FunctionTransformer(cleaning)\n",
    "    vectorizer = TfidfVectorizer(min_df=10, max_df=0.7, ngram_range=(1, 1))\n",
    "    model = MultinomialNB(alpha=10)\n",
    "    pipeline = make_pipeline(cleaner, vectorizer, model)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # evaluate the pipeline\n",
    "    predictions = pipeline.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    print(f\"{ds_name}: accuracy of {round(accuracy*100,1)}%\")    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds-hate: accuracy of 79.5%\n",
      "ds-linguistic: accuracy of 58.4%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "for ds_name, ds in dict_ds_large.items():\n",
    "    \n",
    "    # defining X and y and taking a subset of the full dataset\n",
    "    X_full = ds['text']\n",
    "    y_full = ds['label']\n",
    "    X, _, y, _ = train_test_split(X_full, y_full, test_size=0.75, random_state=42)\n",
    "    \n",
    "    # train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    # make a pipeline and fit it\n",
    "    cleaner = FunctionTransformer(cleaning)\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,1), min_df=30, max_df=0.8)\n",
    "    model = MultinomialNB(alpha=10)\n",
    "    pipeline = make_pipeline(cleaner, vectorizer, model)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # evaluate the pipeline\n",
    "    predictions = pipeline.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "           \n",
    "    print(f\"{ds_name}: accuracy of {round(accuracy*100,1)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fake-news",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
